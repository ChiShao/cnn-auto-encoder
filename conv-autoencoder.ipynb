{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\.conda\\envs\\tf-env\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\danie\\.conda\\envs\\tf-env\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras.layers import (\n",
    "    Conv2D, Dense, Flatten, Input, MaxPooling2D, Reshape, UpSampling2D)\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "ENCODING_DIM = 10\n",
    "\n",
    "# decision boundary for classifier\n",
    "THRESHOLD = 0.7\n",
    "\n",
    "# working directory\n",
    "CUR_DIR = os.path.curdir\n",
    "\n",
    "# setting random seed for reproducable results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_split=0.7, test_split=0.85):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    # define boundaries for train,validation and test set at .7 and .85 % of the MNIST data set\n",
    "    x_len = len(X)\n",
    "    boundaries = [int(x_len * 0.7), int(x_len * 0.85)]\n",
    "\n",
    "    [X_train, X_test, X_validate] = np.split(X, boundaries)\n",
    "\n",
    "    [y_train, y_test, y_validate] = np.split(y, boundaries)\n",
    "    return (X_train, X_test, X_validate), (y_train, y_test, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_split=.7, test_split=.85):\n",
    "    \"\"\"retrieves data MNIST data set and rebalances dataset, such that train=.7, test=.15 and validation=.15\"\"\"\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = X_train.reshape((len(X_train), 28, 28, 1))\n",
    "    test_len = len(X_test)\n",
    "\n",
    "    X_test = X_test.reshape((test_len, 28, 28, 1))\n",
    "\n",
    "    # divide X values bei 255.0 since MNIST data set changed such that pixel values are in [0,255]\n",
    "    X = np.concatenate((X_train, X_test)) / 255.0\n",
    "    y = np.concatenate((y_train, y_test))\n",
    "  \n",
    "    (X_train, X_test, X_validate), (y_train, y_test, y_validate) = train_test_split(X,y) # defaul: .7, .85\n",
    "    # one-hot encode target columns\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    y_validate = to_categorical(y_validate)\n",
    "\n",
    "    return (X_train, X_test, X_validate), (y_train, y_test, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3ffc281748>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADqdJREFUeJzt3X+MVfWZx/HPo7b4o5AwbRyBTqASUfBnNxPSoDFVoYrWIJoYiFGWJR1NmGgTMQj7B8aNCS5rV+IfTaYBimuV1oBhxFpKSbNqXBsRR0TdwoggQ5ihhiLyF0We/WMO3anO+d7h/jp3eN6vZDL3nud+73ly4TPnnnvuOV9zdwGI56yiGwBQDMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoc+q5MjPj64RAjbm7DeVxFW35zewWM/uzmXWb2aOVPBeA+rJyv9tvZmdL2iVphqQeSW9LmuvuHybGsOUHaqweW/6pkrrdfY+7H5e0TtKsCp4PQB1VEv5xkvYPuN+TLfsHZtZmZtvMbFsF6wJQZTX/wM/dOyR1SLztBxpJJVv+A5JaBtz/brYMwDBQSfjflnSJmX3PzL4paY6kzuq0BaDWyn7b7+4nzKxd0mZJZ0ta7e4fVK0zADVV9qG+slbGPj9Qc3X5kg+A4YvwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMqeoluSzGyvpC8kfSnphLu3VqMpnDnWrFmTW5s5c2Zy7PXXX5+s79q1q6ye0K+i8GducPfPqvA8AOqIt/1AUJWG3yX93szeMbO2ajQEoD4qfdt/nbsfMLMLJW0xs/9199cGPiD7o8AfBqDBVLTld/cD2e9Dkl6SNHWQx3S4eysfBgKNpezwm9kFZjby1G1JP5K0s1qNAaitSt72N0t6ycxOPc/z7v67qnQFoObKDr+775F0dRV7CWvEiBHJ+rRp05L12bNnl73uN998M1lft25dsj5q1KhkferUr+0J/t2FF16YHHvxxRcn6xznrwyH+oCgCD8QFOEHgiL8QFCEHwiK8ANBVeOsvhCam5tzayNHjkyObWlpSdaXLFmSrE+fPj1ZP3r0aG7t+PHjybHt7e3J+g033JCs7969O1mfPHlybu29995Ljt25k++M1RJbfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iyty9fiszq9/KTtPo0aOT9e3bt+fWxo8fX9G6U8fpJWnPnj3J+uLFi3Nrn3zySXLs448/nqzPnTs3WS/1/6e3tze3ljrdV5J6enqSdQzO3W0oj2PLDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBcT5/5qyz0n8Hzz333Jqte8WKFcn6E088UbN1f/755xWN37FjR7L+4IMP5tY4jl8stvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EFTJ8/nNbLWkH0s65O5XZMuaJP1a0gRJeyXd7e5/LbmyBj6fv5RJkybl1h555JHk2AULFiTr27ZtS9bb2tqS9a6urtxa6lx/qfLvENx5553JemdnZ0XPj9NXzfP5fynplq8se1TSVne/RNLW7D6AYaRk+N39NUmHv7J4lqS12e21ku6ocl8Aaqzcff5mdz+Y3e6VlD+XFYCGVPF3+93dU/vyZtYmKb3TCqDuyt3y95nZGEnKfh/Ke6C7d7h7q7u3lrkuADVQbvg7Jc3Lbs+TtLE67QCol5LhN7MXJP2PpEvNrMfMFkhaLmmGme2WND27D2AY4br9VXD++ecn65s3b07Wr7322mT9yJEjyfq+fftya5dffnly7DnnpD/2eeaZZ5L1hx56KFlH/XHdfgBJhB8IivADQRF+ICjCDwRF+IGgONRXB2PHjk3W77///mR94cKFyXpTU9Np9zRUfX19yfrSpUuT9ddffz231t3dXVZPSONQH4Akwg8ERfiBoAg/EBThB4Ii/EBQhB8IiuP8w8D8+fOT9VWrVtVs3WbpQ8al/v8cPXo0t/b8888nxz755JPJeupU5sg4zg8gifADQRF+ICjCDwRF+IGgCD8QFOEHgqp4ui7U3tVXX1322FLTf998883J+rRp0yqq33bbbbm1Bx54IDn2pptuStanT5+erO/fvz9Zj44tPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVfJ8fjNbLenHkg65+xXZssck/UTSX7KHLXX335ZcGefzD2rixInJ+htvvJGsX3TRRbm1p556Kjl20aJFyXqlUnMKLFu2LDm21HwFpc7nv/HGG8seO5xV83z+X0q6ZZDl/+nu12Q/JYMPoLGUDL+7vybpcB16AVBHlezzt5vZDjNbbWajq9YRgLooN/w/lzRR0jWSDkrK3bE0szYz22Zm6S+ZA6irssLv7n3u/qW7n5T0C0lTE4/tcPdWd28tt0kA1VdW+M1szIC7syXtrE47AOql5Cm9ZvaCpB9K+o6Z9UhaJumHZnaNJJe0V1J6jmkADYfr9g8D7777brKeOt9/7NixybG9vb1l9VQPL774YrJ+1113Jesvv/xy2WNPnDiRrDcyrtsPIInwA0ERfiAowg8ERfiBoAg/EBSX7h4GNm3alKynDvWlLp0t1XZ670q1t7cn6y0tLcn67bffnlubMGFCcmx3d3eyfiZgyw8ERfiBoAg/EBThB4Ii/EBQhB8IivADQXFK7zAwY8aMZD116uqGDRuSY0v9+99zzz3JepFmzpyZrL/yyiu5tcWLFyfHrlixoqyeGgGn9AJIIvxAUIQfCIrwA0ERfiAowg8ERfiBoDiffxjYsmVLsr5///7c2pw5cypa95IlS5L1Tz/9tKLnL8pll11WdAuFY8sPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GVPJ/fzFokPSupWZJL6nD3lWbWJOnXkiZI2ivpbnf/a4nn4nz+Gpg/f35ubdGiRcmxkydPTtZLHcd/+OGHk/X169cn65VoampK1t96663c2qhRo5Jjp0yZkqwfPnw4WS9SNc/nPyHpYXefIukHkhaa2RRJj0ra6u6XSNqa3QcwTJQMv7sfdPft2e0vJH0kaZykWZLWZg9bK+mOWjUJoPpOa5/fzCZI+r6kP0lqdveDWalX/bsFAIaJIX+338y+JWm9pJ+6+1Gz/9+tcHfP2583szZJbZU2CqC6hrTlN7NvqD/4v3L3U1eE7DOzMVl9jKRDg4119w53b3X31mo0DKA6Sobf+jfxqyR95O4/G1DqlDQvuz1P0sbqtwegVobytv9aSfdKet/MurJlSyUtl/QbM1sgaZ+ku2vTIkpZs2ZNbq23tzc5trOzM1kfP358sv70008n6ydOnMitbdxY2fai1OG4cePG5db6+vqSY0+ePFlWT8NJyfC7+xuS8o4b3lTddgDUC9/wA4Ii/EBQhB8IivADQRF+ICjCDwTFpbvPcK+++mqyfumllybrH3/8cbKeOpYuScuXL0/WU0p9D2DkyJHJ+nnnnZdbW7lyZXLskSNHkvUzAVt+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiq5KW7q7oyLt097Nx7773J+tq1a5P1lNS5/pLU1dWVrI8YMSJZv/LKK3NrkyZNSo7t7u5O1htZNS/dDeAMRPiBoAg/EBThB4Ii/EBQhB8IivADQXE+P5Kee+65ZP3YsWPJ+rJly3JrV111VXJsa2t6kqdS1xq47777cmt79uxJjo2ALT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBFXyfH4za5H0rKRmSS6pw91Xmtljkn4i6S/ZQ5e6+29LPBfn8wM1NtTz+YcS/jGSxrj7djMbKekdSXdIulvSMXf/j6E2RfiB2htq+Et+w8/dD0o6mN3+wsw+kpSepgVAwzutfX4zmyDp+5L+lC1qN7MdZrbazEbnjGkzs21mtq2iTgFU1ZCv4Wdm35L035KecPcNZtYs6TP1fw7wb+rfNfiXEs/B236gxqq2zy9JZvYNSZskbXb3nw1SnyBpk7tfUeJ5CD9QY1W7gKeZmaRVkj4aGPzsg8BTZkvaebpNAijOUD7tv07S65Lel3QyW7xU0lxJ16j/bf9eSfdnHw6mnostP1BjVX3bXy2EH6g9rtsPIInwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVL2n6P5M0r4B97+TLWtEjdpbo/Yl0Vu5qtnb+KE+sK7n839t5Wbb3D09CXtBGrW3Ru1LordyFdUbb/uBoAg/EFTR4e8oeP0pjdpbo/Yl0Vu5Cumt0H1+AMUpessPoCCFhN/MbjGzP5tZt5k9WkQPecxsr5m9b2ZdRU8xlk2DdsjMdg5Y1mRmW8xsd/Z70GnSCurtMTM7kL12XWZ2a0G9tZjZH83sQzP7wMweypYX+tol+irkdav7234zO1vSLkkzJPVIelvSXHf/sK6N5DCzvZJa3b3wY8Jmdr2kY5KePTUbkpn9u6TD7r48+8M52t0XN0hvj+k0Z26uUW95M0v/swp87ao543U1FLHlnyqp2933uPtxSeskzSqgj4bn7q9JOvyVxbMkrc1ur1X/f566y+mtIbj7QXffnt3+QtKpmaULfe0SfRWiiPCPk7R/wP0eNdaU3y7p92b2jpm1Fd3MIJoHzIzUK6m5yGYGUXLm5nr6yszSDfPalTPjdbXxgd/XXefu/yRppqSF2dvbhuT9+2yNdLjm55Imqn8at4OSniqymWxm6fWSfuruRwfWinztBumrkNetiPAfkNQy4P53s2UNwd0PZL8PSXpJ/bspjaTv1CSp2e9DBffzd+7e5+5fuvtJSb9Qga9dNrP0ekm/cvcN2eLCX7vB+irqdSsi/G9LusTMvmdm35Q0R1JnAX18jZldkH0QIzO7QNKP1HizD3dKmpfdnidpY4G9/INGmbk5b2ZpFfzaNdyM1+5e9x9Jt6r/E/+PJf1rET3k9HWxpPeynw+K7k3SC+p/G/g39X82skDStyVtlbRb0h8kNTVQb/+l/tmcd6g/aGMK6u069b+l3yGpK/u5tejXLtFXIa8b3/ADguIDPyAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0fV2vFmYkPovgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, X_test, X_validate), (y_train, y_test, y_validate) = get_data()\n",
    "plt.imshow(X_train[2].reshape((28,28)),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_data_set(X, y, digit):\n",
    "    # parameters are training AND test data for X respectively y \n",
    "    # is assumed to be in one-hot-encoding\n",
    "    y = np.argmax(y, axis=1)\n",
    "    indices = np.where(y == digit)\n",
    "\n",
    "    # filtering by the passed digit. needs to be an int\n",
    "    X_digit = X[indices]    \n",
    "    y_digit = y[indices]\n",
    "     \n",
    "    y_digit = to_categorical(y_digit) # array of length 2 of form [0., 1.]\n",
    "    \n",
    "    # splitting in training and test sets is not necessary, \n",
    "    # because anomaly detection without knowledge of the labels is aimed for.\n",
    "    \n",
    "    return X_digit, y_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X_train, X_test, X_validate))\n",
    "y = np.concatenate((y_train, y_test, y_validate))\n",
    "\n",
    "# digit = 0\n",
    "# X_zero, y_zero = get_specific_data_set(X, y, digit)\n",
    "# digit = 8\n",
    "# X_eight, y_eight = get_specific_data_set(X, y, digit)\n",
    "# digit = 1\n",
    "# X_one, y_one =  get_specific_data_set(X, y, digit)\n",
    "# digit = 7\n",
    "# X_seven, y_seven = get_specific_data_set(X, y, digit)\n",
    "digit_data = [get_specific_data_set(X, y, i) for i in range(10)]\n",
    "len(digit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(len(digit_data[1][0][0]))[:8]:\n",
    "    ax = plt.subplot(2, 8, i+1)\n",
    "    plt.imshow(digit_data[1][0][i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "for i in range(len(digit_data[1][0][0]))[:8]:\n",
    "    ax = plt.subplot(2, 8, 8+i+1)\n",
    "    plt.imshow(digit_data[7][0][i].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(input_dim):\n",
    "    \"\"\"Builds classifier for classification of MNIST encoded representation.\"\"\"\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(32, activation=\"relu\", input_dim=input_dim,\n",
    "                         kernel_initializer=\"random_normal\"))\n",
    "    classifier.add(Dense(ENCODING_DIM, activation=\"softmax\",\n",
    "                         kernel_initializer=\"random_normal\"))\n",
    "\n",
    "    classifier.compile(optimizer='adam', loss='mean_squared_error',\n",
    "                       metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_aue():\n",
    "    INPUT_SHAPE = (28, 28, 1)\n",
    "    DEFAULT_KERNEL = (3, 3)\n",
    "    DEFAULT_POOL_SIZE = (2, 2)\n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=INPUT_SHAPE)\n",
    "    # layer between input and middle layer\n",
    "    encode = Conv2D(16, DEFAULT_KERNEL, activation=\"relu\",\n",
    "                    padding=\"same\")(input_img)\n",
    "    encode = MaxPooling2D(DEFAULT_POOL_SIZE, padding=\"same\")(encode)\n",
    "    encode = Conv2D(8, DEFAULT_KERNEL, activation=\"relu\",\n",
    "                    padding=\"same\")(encode)\n",
    "    encode = MaxPooling2D(DEFAULT_POOL_SIZE, padding=\"same\")(encode)\n",
    "    encode = Conv2D(8, DEFAULT_KERNEL, activation=\"relu\",\n",
    "                    padding=\"same\")(encode)\n",
    "    encode = MaxPooling2D(DEFAULT_POOL_SIZE, padding=\"same\")(encode)\n",
    "    encode = Conv2D(6, DEFAULT_KERNEL, activation=\"relu\",\n",
    "                    padding=\"same\")(encode)\n",
    "\n",
    "    # \"encoded\" is the encoded representation of the input, middle layer of the aue\n",
    "    encoded = MaxPooling2D(\n",
    "        DEFAULT_POOL_SIZE, padding=\"same\", name=\"encoder\")(encode)\n",
    "\n",
    "    # layer between middle and output layer\n",
    "    decode = Conv2D(6, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\"\n",
    "                    )(encoded)\n",
    "    decode = UpSampling2D(DEFAULT_POOL_SIZE)(decode)\n",
    "    decode = Conv2D(8, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\"\n",
    "                    )(decode)\n",
    "    decode = UpSampling2D(DEFAULT_POOL_SIZE)(decode)\n",
    "    decode = Conv2D(8, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\"\n",
    "                    )(decode)\n",
    "    decode = UpSampling2D(DEFAULT_POOL_SIZE)(decode)\n",
    "    decode = Conv2D(16, DEFAULT_KERNEL, activation=\"relu\")(decode)\n",
    "    decode = UpSampling2D(DEFAULT_POOL_SIZE)(decode)\n",
    "    decoded = Conv2D(1, DEFAULT_KERNEL, activation=\"sigmoid\",\n",
    "                     padding=\"same\")(decode)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(inputs=input_img, outputs=decoded)\n",
    "\n",
    "    encoder, decoder = get_codec_from_aue(autoencoder)\n",
    "\n",
    "    # build (aka \"compile\") the model\n",
    "    autoencoder.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")\n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codec_from_aue(autoencoder):\n",
    "    encoder_layer = autoencoder.get_layer(\"encoder\")\n",
    "    # this model maps an input to its encoded representation; Big image to small rep\n",
    "    encoder = Model(\n",
    "        inputs=autoencoder.input, outputs=encoder_layer.output)\n",
    "\n",
    "    # create a placeholder for an encoded (ENCODING_DIM-dimensional) input\n",
    "    encoded_input = Input(shape=encoder_layer.output_shape[1:])\n",
    "\n",
    "    # getting the middle of the autoencoder\n",
    "    start = (len(autoencoder.layers))//2\n",
    "    decoder = autoencoder.layers[-start](encoded_input)\n",
    "    # stacking the decoder layers\n",
    "    for i in range(start-1, 0, -1):\n",
    "        decoder = autoencoder.layers[-i](decoder)\n",
    "\n",
    "    # create the decoder model; \"<\": encoded(small) representation to big image\n",
    "    decoder = Model(encoded_input, decoder)\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array to map digits to verbose representation to store model with appropriate naming\n",
    "digits_verbose = [\"zero\", \"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**all digits auto encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder for all digits...\n",
      "Train on 49000 samples, validate on 10500 samples\n",
      "Epoch 1/128\n",
      "49000/49000 [==============================] - 7s 150us/step - loss: 0.2655 - val_loss: 0.2183\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21827, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 2/128\n",
      "49000/49000 [==============================] - 6s 129us/step - loss: 0.2102 - val_loss: 0.1954\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21827 to 0.19543, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 3/128\n",
      "49000/49000 [==============================] - 6s 130us/step - loss: 0.1913 - val_loss: 0.1825\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19543 to 0.18248, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 4/128\n",
      "49000/49000 [==============================] - 6s 126us/step - loss: 0.1805 - val_loss: 0.1845\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.18248\n",
      "Epoch 5/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1736 - val_loss: 0.1686\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18248 to 0.16859, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 6/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1688 - val_loss: 0.1684\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16859 to 0.16840, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 7/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1653 - val_loss: 0.1637\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.16840 to 0.16365, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 8/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1619 - val_loss: 0.1602\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.16365 to 0.16017, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 9/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1583 - val_loss: 0.1613\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16017\n",
      "Epoch 11/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1563 - val_loss: 0.1575\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.16017 to 0.15749, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 12/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1548 - val_loss: 0.1544\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.15749 to 0.15444, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 13/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1535 - val_loss: 0.1505\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.15444 to 0.15047, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 14/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1522 - val_loss: 0.1476\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.15047 to 0.14759, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 15/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1506 - val_loss: 0.1482\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.14759\n",
      "Epoch 16/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1483 - val_loss: 0.1475\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.14759 to 0.14753, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.3.\n",
      "Epoch 18/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1356 - val_loss: 0.1365\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.13668 to 0.13649, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 24/128\n",
      "49000/49000 [==============================] - 6s 126us/step - loss: 0.1352 - val_loss: 0.1359\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.13649 to 0.13589, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 25/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1346 - val_loss: 0.1373\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.13589\n",
      "Epoch 26/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1336 - val_loss: 0.1344\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.13386\n",
      "Epoch 28/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1331 - val_loss: 0.1328\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.13386 to 0.13284, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 29/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1328 - val_loss: 0.1341\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.13284\n",
      "Epoch 30/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1323 - val_loss: 0.1320\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.13284 to 0.13201, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 31/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1320 - val_loss: 0.1315\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.13201 to 0.13149, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 32/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1314 - val_loss: 0.1313\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.13149 to 0.13135, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 33/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1311 - val_loss: 0.1324\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.13135\n",
      "Epoch 34/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1310 - val_loss: 0.1308\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.13135 to 0.13077, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 35/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1306 - val_loss: 0.1307\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.13077 to 0.13074, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 36/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1305 - val_loss: 0.1311\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.13074\n",
      "Epoch 37/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1303 - val_loss: 0.1295\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.13074 to 0.12955, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 38/128\n",
      "49000/49000 [==============================] - 6s 122us/step - loss: 0.1300 - val_loss: 0.1325\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.12955\n",
      "Epoch 39/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1294 - val_loss: 0.1299\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.12955\n",
      "Epoch 40/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1294 - val_loss: 0.1293\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.12955 to 0.12930, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 41/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1292 - val_loss: 0.1292\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.12930 to 0.12924, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 42/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1290 - val_loss: 0.1310\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.12924\n",
      "Epoch 43/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1264 - val_loss: 0.1265\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.12924 to 0.12650, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 45/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1262 - val_loss: 0.1264\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12650 to 0.12641, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 46/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1260 - val_loss: 0.1262\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12641 to 0.12623, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 47/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1259 - val_loss: 0.1262\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12623 to 0.12618, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 48/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1256 - val_loss: 0.1258\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.12592 to 0.12576, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 50/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1255 - val_loss: 0.1256\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.12576 to 0.12561, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 51/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1253 - val_loss: 0.1254\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.12555 to 0.12537, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 53/128\n",
      "49000/49000 [==============================] - 6s 129us/step - loss: 0.1251 - val_loss: 0.1252\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.12537 to 0.12524, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 54/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1249 - val_loss: 0.1250\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.12513 to 0.12498, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 56/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1248 - val_loss: 0.1249\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.12498 to 0.12492, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 57/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1247 - val_loss: 0.1249\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.12492 to 0.12488, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 58/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1246 - val_loss: 0.1247\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.12488 to 0.12472, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 59/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1245 - val_loss: 0.1247\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.12472 to 0.12467, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 60/128\n",
      "49000/49000 [==============================] - 6s 125us/step - loss: 0.1243 - val_loss: 0.1245\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.12467 to 0.12447, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 61/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1241 - val_loss: 0.1242\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.12435 to 0.12423, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 63/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1240 - val_loss: 0.1242\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.12423 to 0.12421, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 64/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1240 - val_loss: 0.1241\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.12421 to 0.12406, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 65/128\n",
      "49000/49000 [==============================] - 6s 126us/step - loss: 0.1238 - val_loss: 0.1239\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.12404 to 0.12386, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 67/128\n",
      "49000/49000 [==============================] - 6s 127us/step - loss: 0.1237 - val_loss: 0.1237\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.12386 to 0.12374, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 68/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1236 - val_loss: 0.1236\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.12374 to 0.12363, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 69/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1235 - val_loss: 0.1236\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.12363 to 0.12361, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 70/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1234 - val_loss: 0.1236\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.12361 to 0.12358, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 71/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1229 - val_loss: 0.1230\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.12301 to 0.12300, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 77/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1228 - val_loss: 0.1229\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.12300 to 0.12288, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 78/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1227 - val_loss: 0.1228\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.12288 to 0.12277, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 79/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1225 - val_loss: 0.1227\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.12277 to 0.12273, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.027000001072883605.\n",
      "Epoch 82/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1223 - val_loss: 0.1224\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.12273 to 0.12239, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 83/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1222 - val_loss: 0.1224\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.12239 to 0.12237, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 84/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1222 - val_loss: 0.1223\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.12235 to 0.12233, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.008100000210106373.\n",
      "Epoch 86/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1221 - val_loss: 0.1223\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.12233 to 0.12228, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "Epoch 87/128\n",
      "49000/49000 [==============================] - 6s 124us/step - loss: 0.1221 - val_loss: 0.1223\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.12228\n",
      "Epoch 88/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1221 - val_loss: 0.1223\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.12227 to 0.12226, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0024300000630319116.\n",
      "Epoch 90/128\n",
      "49000/49000 [==============================] - 6s 123us/step - loss: 0.1221 - val_loss: 0.1222\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.12225 to 0.12224, saving model to ./ckpts/all-conv-ae.hdf5\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0007290000328794121.\n",
      "Epoch 00092: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 4, 4, 6)           438       \n",
      "_________________________________________________________________\n",
      "encoder (MaxPooling2D)       (None, 2, 2, 6)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 6)           330       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 4, 4, 6)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 4, 4, 8)           440       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 5,009\n",
      "Trainable params: 5,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ckpt_loc = os.path.join(CUR_DIR, \"ckpts\", \"all-conv-ae.hdf5\")\n",
    "\n",
    "if(os.path.isfile(ckpt_loc)):\n",
    "    print(\"Loading Autoencoder for all digits from directory %s...\" % ckpt_loc)\n",
    "    all_ae = load_model(ckpt_loc)\n",
    "    all_encoder, all_decoder = get_codec_from_aue(all_ae)\n",
    "else:\n",
    "    print(\"Training Autoencoder for all digits...\")\n",
    "    all_ae, all_encoder, all_decoder = build_conv_aue()\n",
    "    earlyStopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=10, verbose=1, mode='min', min_delta=0.0005)\n",
    "    mcp_save = ModelCheckpoint(ckpt_loc,\n",
    "                               save_best_only=True, verbose=1, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.3, patience=3, verbose=1, mode='min')\n",
    "    all_ae.fit(X_train, X_train,\n",
    "                    epochs=128,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_validate, X_validate), callbacks=[earlyStopping, mcp_save, reduce_lr_loss])\n",
    "all_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49000/49000 [==============================] - 5s 98us/step\n",
      "10500/10500 [==============================] - 1s 98us/step\n",
      "10500/10500 [==============================] - 1s 100us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.12209356144982941, 0.12224460220336913, 0.12298451796032134)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train = all_ae.evaluate(X_train, X_train)\n",
    "eval_validate = all_ae.evaluate(X_validate, X_validate)\n",
    "eval_test = all_ae.evaluate(X_test, X_test)\n",
    "eval_train, eval_validate,eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_imgs_train = all_encoder.predict(X_train)\n",
    "encoded_imgs_validate = all_encoder.predict(X_validate)\n",
    "encoded_imgs_test = all_encoder.predict(X_test)\n",
    "\n",
    "decoded_imgs = all_decoder.predict(encoded_imgs_test)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(os.path.join(\"imgs\", \"all-conv-ae.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"one\" auto encoder**\n",
    "\n",
    "Learning features of the digit one. Afterwards, the distribution of the features will be computed to detect outliers which have low probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5513, 1182, 1182)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_one = digit_data[1][0]\n",
    "y_one = digit_data[1][1]\n",
    "\n",
    "(X_one_train, X_one_test, X_one_validate), (y_one_train, y_one_test, y_one_validate) = train_test_split(X_one, y_one)\n",
    "len(X_one_train), len(X_one_test), len(X_one_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder for digit one...\n",
      "Train on 5513 samples, validate on 1182 samples\n",
      "Epoch 1/128\n",
      "5513/5513 [==============================] - 2s 273us/step - loss: 0.2806 - val_loss: 0.1422\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14225, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 2/128\n",
      "5513/5513 [==============================] - 1s 141us/step - loss: 0.1391 - val_loss: 0.1300\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14225 to 0.12999, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 3/128\n",
      "5513/5513 [==============================] - 1s 141us/step - loss: 0.1300 - val_loss: 0.1246\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12999 to 0.12456, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 4/128\n",
      "5513/5513 [==============================] - 1s 140us/step - loss: 0.1228 - val_loss: 0.1165\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.12456 to 0.11646, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 5/128\n",
      "5513/5513 [==============================] - 1s 134us/step - loss: 0.1147 - val_loss: 0.1127\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11646 to 0.11273, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 6/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.1051 - val_loss: 0.0978\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11273 to 0.09777, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 7/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0981 - val_loss: 0.0972\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09777 to 0.09720, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 8/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0938 - val_loss: 0.0949\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09720 to 0.09491, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 9/128\n",
      "5513/5513 [==============================] - 1s 127us/step - loss: 0.0904 - val_loss: 0.0901\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09491 to 0.09012, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 10/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0875 - val_loss: 0.0933\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09012\n",
      "Epoch 11/128\n",
      "5513/5513 [==============================] - 1s 127us/step - loss: 0.0851 - val_loss: 0.0894\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09012 to 0.08944, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 12/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0838 - val_loss: 0.0786\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08944 to 0.07861, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 13/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0808 - val_loss: 0.0831\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.07861\n",
      "Epoch 14/128\n",
      "5513/5513 [==============================] - 1s 127us/step - loss: 0.0791 - val_loss: 0.0799\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.07861\n",
      "Epoch 15/128\n",
      "5513/5513 [==============================] - 1s 126us/step - loss: 0.0770 - val_loss: 0.0937\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.07861\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.3.\n",
      "Epoch 16/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0700 - val_loss: 0.0677\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.07861 to 0.06771, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 17/128\n",
      "5513/5513 [==============================] - 1s 131us/step - loss: 0.0677 - val_loss: 0.0681\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.06771\n",
      "Epoch 18/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0670 - val_loss: 0.0668\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.06771 to 0.06678, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 19/128\n",
      "5513/5513 [==============================] - 1s 127us/step - loss: 0.0668 - val_loss: 0.0658\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06678 to 0.06583, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 20/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0662 - val_loss: 0.0656\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06583 to 0.06563, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 21/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0656 - val_loss: 0.0706\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.06563\n",
      "Epoch 22/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0658 - val_loss: 0.0641\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06563 to 0.06413, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 23/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0652 - val_loss: 0.0645\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.06413\n",
      "Epoch 24/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0651 - val_loss: 0.0641\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06413 to 0.06406, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 25/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0644 - val_loss: 0.0651\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.06406\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.09000000357627869.\n",
      "Epoch 26/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0625 - val_loss: 0.0620\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.06406 to 0.06200, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 27/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0622 - val_loss: 0.0618\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.06200 to 0.06178, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 28/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0620 - val_loss: 0.0618\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06178 to 0.06177, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 29/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0619 - val_loss: 0.0613\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.06177 to 0.06128, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 30/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0617 - val_loss: 0.0616\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.06128\n",
      "Epoch 31/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0615 - val_loss: 0.0610\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.06128 to 0.06099, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 32/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0614 - val_loss: 0.0608\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.06099 to 0.06082, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 33/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0612 - val_loss: 0.0609\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.06082\n",
      "Epoch 34/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0611 - val_loss: 0.0606\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.06082 to 0.06055, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 35/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0610 - val_loss: 0.0605\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.06055 to 0.06051, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 36/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0608 - val_loss: 0.0603\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.06051 to 0.06031, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 37/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0607 - val_loss: 0.0599\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.06031 to 0.05994, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 38/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0605 - val_loss: 0.0601\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05994\n",
      "Epoch 39/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0604 - val_loss: 0.0601\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05994\n",
      "Epoch 40/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0603 - val_loss: 0.0596\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.05994 to 0.05956, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 41/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0602 - val_loss: 0.0594\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.05956 to 0.05940, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 42/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0600 - val_loss: 0.0595\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05940\n",
      "Epoch 43/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0599 - val_loss: 0.0595\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05940\n",
      "Epoch 44/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0598 - val_loss: 0.0596\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05940\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.027000001072883605.\n",
      "Epoch 45/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0597 - val_loss: 0.0590\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.05940 to 0.05901, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 46/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0596 - val_loss: 0.0590\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.05901 to 0.05899, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 47/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0596 - val_loss: 0.0589\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.05899 to 0.05891, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 48/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0596 - val_loss: 0.0589\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.05891 to 0.05889, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 49/128\n",
      "5513/5513 [==============================] - 1s 128us/step - loss: 0.0595 - val_loss: 0.0589\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.05889 to 0.05885, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 50/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0595 - val_loss: 0.0588\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.05885 to 0.05880, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 51/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0594 - val_loss: 0.0588\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.05880 to 0.05877, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 52/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0594 - val_loss: 0.0587\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.05877 to 0.05875, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 53/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0594 - val_loss: 0.0587\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.05875 to 0.05866, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 54/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0593 - val_loss: 0.0587\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.05866 to 0.05866, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 55/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0593 - val_loss: 0.0586\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.05866 to 0.05863, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 56/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0593 - val_loss: 0.0586\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.05863 to 0.05856, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 57/128\n",
      "5513/5513 [==============================] - 1s 129us/step - loss: 0.0592 - val_loss: 0.0585\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.05856 to 0.05851, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 58/128\n",
      "5513/5513 [==============================] - 1s 130us/step - loss: 0.0592 - val_loss: 0.0585\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.05851 to 0.05848, saving model to ./ckpts/one-conv-ae.hdf5\n",
      "Epoch 00058: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 4, 4, 6)           438       \n",
      "_________________________________________________________________\n",
      "encoder (MaxPooling2D)       (None, 2, 2, 6)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 2, 2, 6)           330       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling (None, 4, 4, 6)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 4, 4, 8)           440       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 5,009\n",
      "Trainable params: 5,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ckpt_loc = os.path.join(CUR_DIR, \"ckpts\", \"%s-conv-ae.hdf5\" % digits_verbose[1])\n",
    "\n",
    "if(os.path.isfile(ckpt_loc)):\n",
    "    print(\"Loading Autoencoder %s from directory %s...\" % (digits_verbose[1] ,ckpt_loc))\n",
    "    one_ae = load_model(ckpt_loc)\n",
    "    one_encoder, one_decoder = get_codec_from_aue(one_ae)\n",
    "else:\n",
    "    print(\"Training Autoencoder for digit %s...\" %digits_verbose[1])\n",
    "    one_ae, one_encoder, one_decoder = build_conv_aue()\n",
    "    earlyStopping = EarlyStopping(\n",
    "        monitor='val_loss', patience=10, verbose=1, mode='min', min_delta=0.0005)\n",
    "    mcp_save = ModelCheckpoint(ckpt_loc,\n",
    "                               save_best_only=True, verbose=1, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.3, patience=3, verbose=1, mode='min')\n",
    "    tb = TensorBoard(log_dir='./ckpts', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "    one_ae.fit(X_one_train, X_one_train,\n",
    "                    epochs=128,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_one_validate, X_one_validate), callbacks=[earlyStopping, mcp_save, reduce_lr_loss,tb])\n",
    "one_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5513/5513 [==============================] - 1s 93us/step\n",
      "1182/1182 [==============================] - 0s 96us/step\n",
      "1182/1182 [==============================] - 0s 93us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05916355805714464, 0.05847888652317213, 0.0578022137183425)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_one_train = one_ae.evaluate(X_one_train, X_one_train)\n",
    "eval_one_validate = one_ae.evaluate(X_one_validate, X_one_validate)\n",
    "eval_one_test = one_ae.evaluate(X_one_test, X_one_test)\n",
    "eval_one_train, eval_one_validate, eval_one_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_one_imgs_train = one_encoder.predict(X_one_train)\n",
    "encoded_one_imgs_validate = one_encoder.predict(X_one_validate)\n",
    "encoded_one_imgs_test = one_encoder.predict(X_one_test)\n",
    "\n",
    "decoded_one_imgs = one_decoder.predict(encoded_one_imgs_train)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_one_train[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_one_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(os.path.join(\"imgs\", \"one-conv-ae.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All digits classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = np.prod(encoded_imgs_train.shape[1:], dtype=np.int64)\n",
    "encoded_imgs_train = encoded_imgs_train.reshape(len(encoded_imgs_train), flat)\n",
    "encoded_imgs_validate = encoded_imgs_validate.reshape(\n",
    "    len(encoded_imgs_validate), flat)\n",
    "encoded_imgs_test = encoded_imgs_test.reshape(len(encoded_imgs_test), flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading classifier from directory ./ckpts/classifier.hdf5...\n"
     ]
    }
   ],
   "source": [
    "ckpt_loc = os.path.join(CUR_DIR, \"ckpts\", \"classifier.hdf5\")\n",
    "if(os.path.isfile(ckpt_loc)):\n",
    "    print(\"Loading classifier from directory %s...\" % ckpt_loc)\n",
    "    classifier = load_model(ckpt_loc)\n",
    "else:\n",
    "    print(\"Training classifier...\")\n",
    "    classifier = build_classifier(input_dim=flat)\n",
    "    earlyStopping = EarlyStopping(\n",
    "        monitor='val_acc', patience=5, verbose=1, mode='max',  min_delta=0.0005)\n",
    "    mcp_save = ModelCheckpoint(ckpt_loc,\n",
    "                               save_best_only=True, verbose=1, monitor='val_acc', mode='max')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(\n",
    "        monitor='val_acc', factor=0.3, patience=3, verbose=1, mode='max')\n",
    "    classifier.fit(encoded_imgs_train, y_train, validation_data=(\n",
    "        encoded_imgs_validate, y_validate), batch_size=16, epochs=32, shuffle=True, callbacks=[earlyStopping, mcp_save, reduce_lr_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49000/49000 [==============================] - 3s 52us/step\n",
      "10500/10500 [==============================] - 0s 42us/step\n",
      "10500/10500 [==============================] - 0s 40us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.009988542235627467, 0.9347551020408164],\n",
       " [0.010621404919995085, 0.9284761904761905],\n",
       " [0.01085971777589016, 0.9284761904761905])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_train = classifier.evaluate(encoded_imgs_train, y_train)\n",
    "eval_validate = classifier.evaluate(encoded_imgs_validate, y_validate)\n",
    "eval_test = classifier.evaluate(encoded_imgs_test, y_test)\n",
    "eval_train,eval_validate, eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm(input, y_true):\n",
    "    \"\"\"Computes confusion matrix.\"\"\"\n",
    "    y_pred = tf.argmax(classifier.predict(input), axis=1)\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "\n",
    "    c = tf.keras.backend.eval(y_pred)\n",
    "    d = tf.keras.backend.eval(y_true)\n",
    "\n",
    "    return confusion_matrix(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(cm):\n",
    "    results = []\n",
    "    for i in range(len(cm)):  # rows\n",
    "        TP = cm[i][i]\n",
    "        fp_tp = np.sum(cm[i])\n",
    "        results.append(TP/fp_tp)\n",
    "    return results + [np.mean(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(cm):\n",
    "    results = []\n",
    "    for i in range(len(cm)):  # rows\n",
    "        TP = cm[i][i]\n",
    "        tp_fn = 0\n",
    "        for j in range(len(cm[i])):\n",
    "            tp_fn += cm[j][i]\n",
    "        results.append(TP/tp_fn)\n",
    "    return results + [np.mean(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4800    1   57   27   12   34   34   15   49   57]\n",
      " [   1 5368   14   20   23   10   11   29   32   19]\n",
      " [   4   42 4616  109   34   24    9   56   40   17]\n",
      " [   0   20   56 4525   15  105    2   28   63   55]\n",
      " [   5    4   12    8 4181    9   13   28   33  106]\n",
      " [   8    5    9   82    3 4123   35    7   91   20]\n",
      " [  12    2    8    3   70   39 4739    0   38    0]\n",
      " [   2    7   47   32   10    3    0 4676   13  120]\n",
      " [  27   18   61  111   86   75   25   33 4339   81]\n",
      " [   3   10    9   24  284   22    0  272   48 4436]]\n",
      "0.9347102538187887\n",
      "0.9341304435680249\n",
      "[[ 999    0   19    4    2    9   11    3   16   14]\n",
      " [   0 1182    3    8    7    4    3    8   14    6]\n",
      " [   1   12 1029   15   11    5    0   11    7    5]\n",
      " [   1    3    9  959    2   24    1    6    5   22]\n",
      " [   0    3    3    0  895    2    2    3    6   17]\n",
      " [   3    4    2   22    0  881    6    2   24    8]\n",
      " [   2    1    0    0   15   10  995    0   14    0]\n",
      " [   0    2   12    9    1    0    0  983    3   28]\n",
      " [  11    5   10   23   31   17   13    7  941   16]\n",
      " [   1    4    1    5   55    4    0   59   14  885]]\n",
      "0.9283116726193636\n",
      "0.9275753119607701\n",
      "[[1011    0    8    8    4   16   12    2   10    7]\n",
      " [   0 1165    3    5    5    2    9    3    8    6]\n",
      " [   1    4  956   25   11    1    0   13    9    4]\n",
      " [   0    6   12 1044    1   13    0    5   13   21]\n",
      " [   0    1    5    0  967    2    2   10    6   16]\n",
      " [   3    0    1   24    1  842    8    1   23    8]\n",
      " [   3    2    1    1   13   16  934    0   10    1]\n",
      " [   0    2    9    7    4    1    0  962    2   27]\n",
      " [   5    2   16   33   19   14   12    6  938   26]\n",
      " [   0    2    2    8   62    6    0   65   16  930]]\n",
      "0.9285455098269633\n",
      "0.9284651401159518\n"
     ]
    }
   ],
   "source": [
    "cm_train = get_cm(encoded_imgs_train, y_train)\n",
    "print(cm_train, precision(cm_train)[-1], recall(cm_train)[-1], sep=\"\\n\")\n",
    "\n",
    "cm_validate = get_cm(encoded_imgs_validate, y_validate)\n",
    "print(cm_validate, precision(cm_validate)[-1], recall(cm_validate)[-1], sep=\"\\n\")\n",
    "\n",
    "cm_test = get_cm(encoded_imgs_test, y_test)\n",
    "print(cm_test, precision(cm_test)[-1], recall(cm_test)[-1], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection with DJ CF Gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_flat = np.prod(encoded_one_imgs_train.shape[1:], dtype=np.int64)\n",
    "encoded_one_imgs_train = encoded_one_imgs_train.reshape(len(encoded_one_imgs_train), one_flat)\n",
    "encoded_one_imgs_validate = encoded_one_imgs_validate.reshape(\n",
    "    len(encoded_one_imgs_validate), one_flat)\n",
    "encoded_one_imgs_test = encoded_one_imgs_test.reshape(len(encoded_one_imgs_test), one_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x_i, my_i, sigma_i2):\n",
    "    # gaussian distribution for one feature\n",
    "    if sigma_i2 == 0:\n",
    "        return 1 if x_i == my_i  else 0\n",
    "    return np.array((1/np.sqrt(2*np.pi*sigma_i2)) *\n",
    "                    np.exp(-(x_i-my_i)**2/(2*sigma_i2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my(X):\n",
    "    return np.array([(1 / len(x)) * np.sum(x) for x in X.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma2(X, my):\n",
    "    # computes sigma squared for each feature\n",
    "    m = len(X)  # number of data points\n",
    "    return np.array([(1/m)*np.sum((X[:, i] - my[i]) ** 2) for i in range(len(my))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(X,my,sigma2):\n",
    "    return np.array([np.prod([gauss(x[i], my[i], sigma2[i])\n",
    "               for i in range(len(x))]) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5294757845093415,\n",
       " array([1.84982017e+00, 2.74012420e+00, 2.64077946e+00, 1.43267175e+00,\n",
       "        3.91905142e+00, 2.27522908e+00, 3.63035771e-04, 3.25541618e+00,\n",
       "        6.74511302e-01, 6.01849605e+00, 1.89010351e+00, 2.81298554e+00,\n",
       "        1.12724363e+00, 3.01555627e+00, 2.46752420e+00, 1.79792259e+00,\n",
       "        1.16948558e+00, 1.36342013e+00, 8.52866502e-02, 1.18456757e+00,\n",
       "        2.49557792e+00, 5.19481687e+00, 1.30515116e+00, 2.82049354e+00]),\n",
       " array([2.41987334e-01, 1.83408517e+00, 1.77642671e+00, 8.90007319e-01,\n",
       "        2.17625571e-01, 7.25981708e-01, 6.02347317e-05, 3.85505797e-01,\n",
       "        3.46326629e-01, 1.30616288e+00, 1.96352589e-01, 3.13626466e-01,\n",
       "        1.03905417e-01, 4.48970934e-01, 1.12012339e+00, 7.59588133e-01,\n",
       "        2.14902958e-01, 1.46769246e-01, 2.72530359e-02, 2.83271921e-01,\n",
       "        3.32076465e-01, 2.48776542e+00, 2.55820139e-01, 1.70360978e-01]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = encoded_one_imgs_train\n",
    "m = len(X)\n",
    "number_of_features = len(X[0])\n",
    "my =  np.array([(1 / len(x)) * np.sum(x) for x in X.T])\n",
    "sigma_2 =  np.array([np.sum((X[:, i] - my[i]) ** 2)/m for i in range(number_of_features)])\n",
    "\n",
    "p_all = np.sort(p(X,my,sigma_2))\n",
    "epsilon = 1e-7\n",
    "thresholded_P = p_all[np.where(p_all>epsilon)]\n",
    "len(thresholded_P)/len(p_all), my, sigma_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(len(my)):\n",
    "    # plots distribution of i-th feature\n",
    "    # display original\n",
    "    bins = 50\n",
    "    hist = np.histogram(X[:, i], bins=bins)\n",
    "    ax = plt.subplot(4, 6, i + 1)\n",
    "    h_min = min(hist[1])\n",
    "    h_max = max(hist[1])\n",
    "    delta = abs(h_max - h_min)\n",
    "    step = delta / (bins-1)\n",
    "    r = np.arange(h_min, h_max, step)\n",
    "    plt.plot(r, hist[0])\n",
    "    print(r,hist[0],step)\n",
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_values_to_img(values):\n",
    "    values = np.reshape(values,(1,2,2,6))\n",
    "    random_img = decoder.predict(values)\n",
    "    return np.reshape(random_img, (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 50\n",
    "hist_all = np.histogram(p_all,bins =bins)\n",
    "h_min = min(hist_all[1])\n",
    "h_max = max(hist_all[1])\n",
    "delta = abs(h_max-h_min)\n",
    "r = np.arange(h_min,h_max, delta/bins)\n",
    "plt.plot(r,hist_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting fashion-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion():\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    img = X_train[0].reshape((28, 28))\n",
    "    # reshape data to fit model\n",
    "    plt.imshow(X_train[0], cmap=\"Greys\", vmin=0, vmax=255)\n",
    "    plt.savefig(\"example_img.png\")\n",
    "\n",
    "    \"\"\"for Autoencoder\"\"\"\n",
    "    X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "    X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "    np.random.shuffle(X_test)\n",
    "    X_validate = X_test[len(X_test)//2:]\n",
    "    X_test = X_test[:len(X_test)//2]\n",
    "\n",
    "    return X_train/255.0, X_test/255.0, X_validate/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 13s 1us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "assignment destination is read-only",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-47eb5ba7a2d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_fashion_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fashion_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_fashion_validate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_fashion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fashion_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-70a604210eff>\u001b[0m in \u001b[0;36mget_fashion\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mX_validate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.shuffle\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.shuffle\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: assignment destination is read-only"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_fashion_train, X_fashion_test, X_fashion_validate = get_fashion()\n",
    "print(X_fashion_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
