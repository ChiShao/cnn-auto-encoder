{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "from keras.datasets import mnist, fashion_mnist, cifar10, cifar100\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPooling2D,\n",
    "    Reshape,\n",
    "    UpSampling2D,\n",
    ")\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CIFAR_10 = cifar10.load_data()\n",
    "#CIFAR_100 = cifar100.load_data()\n",
    "#MNIST = mnist.load_data()\n",
    "FASHION_MNIST = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "ENCODING_DIM = 10\n",
    "\n",
    "# decision boundary for classifier\n",
    "THRESHOLD = 0.7\n",
    "\n",
    "# working directory\n",
    "CUR_DIR = os.path.abspath(os.path.curdir)\n",
    "\n",
    "# setting random seed for reproducable results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_split=0.7, test_split=0.85):\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    # define boundaries for train,validation and test set at .7 and .85 % of the MNIST data set\n",
    "    x_len = len(X)\n",
    "    boundaries = [int(x_len * train_split), int(x_len * test_split)]\n",
    "\n",
    "    [X_train, X_test, X_validate] = np.split(X, boundaries)\n",
    "\n",
    "    [y_train, y_test, y_validate] = np.split(y, boundaries)\n",
    "    return (X_train, X_test, X_validate), (y_train, y_test, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset, train_split=0.7, test_split=0.85):\n",
    "    \"\"\"retrieves data set and rebalances dataset, such that train=.7, test=.15 and validation=.15.\n",
    "    :param dataset is assumed to be loaded from keras.datasets, thus the from 2-tuple(2-tuple) is assumed.\"\"\"\n",
    "    if not (len(dataset) == 2 and all([len(d) == 2 for d in dataset])):\n",
    "        raise ValueError(\n",
    "            \"Datset has not the correct form. Please load from keras.datasets or convert to similar form.\"\n",
    "        )\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = dataset\n",
    "    if len(X_train.shape) == 3: # MNIST data set\n",
    "        X_train = X_train.reshape((list(X_train.shape) + [1])) /255.0\n",
    "        test_len = len(X_test)\n",
    "        X_test = X_test.reshape((list(X_test.shape) + [1])) / 255.0\n",
    "\n",
    "    # divide X values bei 255.0 since MNIST data set changed such that pixel values are in [0,255]\n",
    "    X = np.concatenate((X_train, X_test)) \n",
    "    y = np.concatenate((y_train, y_test))\n",
    "\n",
    "    (X_train, X_test, X_validate), (y_train, y_test, y_validate) = train_test_split(\n",
    "        X, y\n",
    "    )  # default: .7, .85\n",
    "    # one-hot encode target columns\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    y_validate = to_categorical(y_validate)\n",
    "\n",
    "    return (X_train, X_test, X_validate), (y_train, y_test, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, X_validate), (y_train, y_test, y_validate) = get_data(FASHION_MNIST)\n",
    "#plt.imshow(X_train[3].reshape((28,28)),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_data_set(X, y, digit):\n",
    "    # parameters are training AND test data for X respectively y \n",
    "    # is assumed to be in one-hot-encoding\n",
    "    y = np.argmax(y, axis=1)\n",
    "    indices = np.where(y == digit)\n",
    "\n",
    "    # filtering by the passed digit. needs to be an int\n",
    "    X_digit = X[indices]    \n",
    "    y_digit = y[indices]\n",
    "     \n",
    "    y_digit = to_categorical(y_digit) # array of length 2 of form [0., 1.]\n",
    "    \n",
    "    # splitting into training and test set is not necessary since the data for single digits\n",
    "    # is just used for evaluation purposes (except for \"1\")\n",
    "    \n",
    "    return [X_digit, y_digit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 28, 28, 1), (70000, 10))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X_train, X_test, X_validate))\n",
    "y = np.concatenate((y_train, y_test, y_validate))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit = 0\n",
    "# X_zero, y_zero = get_specific_data_set(X, y, digit)\n",
    "# digit = 8\n",
    "# X_eight, y_eight = get_specific_data_set(X, y, digit)\n",
    "# digit = 1\n",
    "# X_one, y_one =  get_specific_data_set(X, y, digit)\n",
    "# digit = 7\n",
    "# X_seven, y_seven = get_specific_data_set(X, y, digit)\n",
    "digit_data = [get_specific_data_set(X, y, i) for i in range(10)]\n",
    "\n",
    "all_digits = X[np.where(np.argmax(y,axis=1)!= 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(len(digit_data[1][0][0]))[:8]:\n",
    "    ax = plt.subplot(2, 8, i+1)\n",
    "    plt.imshow(digit_data[0][0][i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "for i in range(len(digit_data[1][0][0]))[:8]:\n",
    "    ax = plt.subplot(2, 8, 8+i+1)\n",
    "    plt.imshow(digit_data[2][0][i].reshape(28, 28))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(input_dim):\n",
    "    \"\"\"Builds classifier for classification of MNIST encoded representation.\"\"\"\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(32, activation=\"relu\", input_dim=input_dim,\n",
    "                         kernel_initializer=\"random_normal\"))\n",
    "    classifier.add(Dense(ENCODING_DIM, activation=\"softmax\",\n",
    "                         kernel_initializer=\"random_normal\"))\n",
    "\n",
    "    classifier.compile(optimizer='adam', loss='mean_squared_error',\n",
    "                       metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_aue():\n",
    "    INPUT_SHAPE = (28, 28, 1)\n",
    "    DEFAULT_KERNEL = (3, 3)\n",
    "    DEFAULT_POOL_SIZE = (2, 2)\n",
    "    # this is our input placeholder\n",
    "    input_img = Input(shape=INPUT_SHAPE)\n",
    "    # layer between input and middle layer\n",
    "    encode = Conv2D(16, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\")(input_img)\n",
    "    encode = MaxPooling2D(DEFAULT_POOL_SIZE, padding=\"same\")(encode)\n",
    "    encode = Conv2D(8, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\")(encode)\n",
    "    encode = MaxPooling2D(DEFAULT_POOL_SIZE, padding=\"same\")(encode)\n",
    "    encode = Conv2D(8, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\")(encode)\n",
    "    encode = MaxPooling2D(DEFAULT_POOL_SIZE, padding=\"same\")(encode)\n",
    "    encode = Conv2D(6, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\")(encode)\n",
    "\n",
    "    # \"encoded\" is the encoded representation of the input, middle layer of the aue\n",
    "    encoded = MaxPooling2D(DEFAULT_POOL_SIZE, padding=\"same\", name=\"encoder\")(encode)\n",
    "\n",
    "    # layer between middle and output layer\n",
    "    decode = Conv2D(6, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\")(encoded)\n",
    "    decode = UpSampling2D(DEFAULT_POOL_SIZE)(decode)\n",
    "    decode = Conv2D(8, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\")(decode)\n",
    "    decode = UpSampling2D(DEFAULT_POOL_SIZE)(decode)\n",
    "    decode = Conv2D(8, DEFAULT_KERNEL, activation=\"relu\", padding=\"same\")(decode)\n",
    "    decode = UpSampling2D(DEFAULT_POOL_SIZE)(decode)\n",
    "    decode = Conv2D(16, DEFAULT_KERNEL, activation=\"relu\")(decode)\n",
    "    decode = UpSampling2D(DEFAULT_POOL_SIZE)(decode)\n",
    "    decoded = Conv2D(1, DEFAULT_KERNEL, activation=\"sigmoid\", padding=\"same\")(decode)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(inputs=input_img, outputs=decoded)\n",
    "\n",
    "    encoder, decoder = get_codec_from_aue(autoencoder)\n",
    "\n",
    "    # build (aka \"compile\") the model\n",
    "    autoencoder.compile(optimizer=\"adadelta\", loss=\"binary_crossentropy\")\n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codec_from_aue(autoencoder):\n",
    "    encoder_layer = autoencoder.get_layer(\"encoder\")\n",
    "    # this model maps an input to its encoded representation; Big image to small rep\n",
    "    encoder = Model(\n",
    "        inputs=autoencoder.input, outputs=encoder_layer.output)\n",
    "\n",
    "    # create a placeholder for an encoded (ENCODING_DIM-dimensional) input\n",
    "    encoded_input = Input(shape=encoder_layer.output_shape[1:])\n",
    "\n",
    "    # getting the middle of the autoencoder\n",
    "    start = (len(autoencoder.layers))//2\n",
    "    decoder = autoencoder.layers[-start](encoded_input)\n",
    "    # stacking the decoder layers\n",
    "    for i in range(start-1, 0, -1):\n",
    "        decoder = autoencoder.layers[-i](decoder)\n",
    "\n",
    "    # create the decoder model; \"<\": encoded(small) representation to big image\n",
    "    decoder = Model(encoded_input, decoder)\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array to map digits to verbose representation to store model with appropriate naming\n",
    "digits_verbose = [\n",
    "    \"zero\",\n",
    "    \"one\",\n",
    "    \"two\",\n",
    "    \"three\",\n",
    "    \"four\",\n",
    "    \"five\",\n",
    "    \"six\",\n",
    "    \"seven\",\n",
    "    \"eight\",\n",
    "    \"nine\",\n",
    "]\n",
    "fashion_verbose = [\n",
    "    \"t-shirt\",\n",
    "    \"trousers\",\n",
    "    \"pullover\",\n",
    "    \"dress\",\n",
    "    \"coat\",\n",
    "    \"sandal\",\n",
    "    \"shirt\",\n",
    "    \"sneaker\",\n",
    "    \"bag\",\n",
    "    \"ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**all digits auto encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_loc = os.path.join(CUR_DIR, \"ckpts\", \"fashionall-conv-ae.hdf5\")\n",
    "\n",
    "if os.path.isfile(ckpt_loc):\n",
    "    print(\"Loading Autoencoder for all digits from directory %s...\" % ckpt_loc)\n",
    "    all_ae = load_model(ckpt_loc)\n",
    "    all_encoder, all_decoder = get_codec_from_aue(all_ae)\n",
    "else:\n",
    "    print(\"Training Autoencoder for all digits...\")\n",
    "    all_ae, all_encoder, all_decoder = build_conv_aue()\n",
    "    earlyStopping = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, verbose=1, mode=\"min\", min_delta=0.0005\n",
    "    )\n",
    "    mcp_save = ModelCheckpoint(\n",
    "        ckpt_loc, save_best_only=True, verbose=1, monitor=\"val_loss\", mode=\"min\"\n",
    "    )\n",
    "    reduce_lr_loss = ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.3, patience=3, verbose=1, mode=\"min\"\n",
    "    )\n",
    "    all_ae.fit(\n",
    "        X_train,\n",
    "        X_train,\n",
    "        epochs=128,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_validate, X_validate),\n",
    "        callbacks=[earlyStopping, mcp_save, reduce_lr_loss],\n",
    "    )\n",
    "all_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_train = all_ae.evaluate(X_train, X_train)\n",
    "eval_validate = all_ae.evaluate(X_validate, X_validate)\n",
    "eval_test = all_ae.evaluate(X_test, X_test)\n",
    "eval_train, eval_validate,eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_train = all_encoder.predict(X_train)\n",
    "encoded_imgs_validate = all_encoder.predict(X_validate)\n",
    "encoded_imgs_test = all_encoder.predict(X_test)\n",
    "\n",
    "decoded_imgs = all_decoder.predict(encoded_imgs_test)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(os.path.join(\"imgs\", \"all-conv-ae.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"one\" auto encoder**\n",
    "\n",
    "Learning features of the digit one. Afterwards, the distribution of the features will be computed to detect outliers which have low probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one = digit_data[1][0]\n",
    "y_one = digit_data[1][1]\n",
    "\n",
    "(X_one_train, X_one_test, X_one_validate), (\n",
    "    y_one_train,\n",
    "    y_one_test,\n",
    "    y_one_validate,\n",
    ") = train_test_split(X_one, y_one)\n",
    "len(X_one_train), len(X_one_test), len(X_one_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_loc = os.path.join(CUR_DIR, \"ckpts\", \"%s-conv-ae.hdf5\" % digits_verbose[1])\n",
    "\n",
    "if os.path.isfile(ckpt_loc):\n",
    "    print(\"Loading Autoencoder %s from directory %s...\" % (digits_verbose[1], ckpt_loc))\n",
    "    one_ae = load_model(ckpt_loc)\n",
    "    one_encoder, one_decoder = get_codec_from_aue(one_ae)\n",
    "else:\n",
    "    print(\"Training Autoencoder for digit %s...\" % digits_verbose[1])\n",
    "    one_ae, one_encoder, one_decoder = build_conv_aue()\n",
    "    earlyStopping = EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, verbose=1, mode=\"min\", min_delta=0.0005\n",
    "    )\n",
    "    mcp_save = ModelCheckpoint(\n",
    "        ckpt_loc, save_best_only=True, verbose=1, monitor=\"val_loss\", mode=\"min\"\n",
    "    )\n",
    "    reduce_lr_loss = ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.3, patience=3, verbose=1, mode=\"min\"\n",
    "    )\n",
    "    tb = TensorBoard(\n",
    "        log_dir=\"./ckpts\", histogram_freq=0, write_graph=True, write_images=True\n",
    "    )\n",
    "    one_ae.fit(\n",
    "        X_one_train,\n",
    "        X_one_train,\n",
    "        epochs=128,\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        validation_data=(X_one_validate, X_one_validate),\n",
    "        callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tb],\n",
    "    )\n",
    "one_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_one_train = one_ae.evaluate(X_one_train, X_one_train)\n",
    "eval_one_validate = one_ae.evaluate(X_one_validate, X_one_validate)\n",
    "eval_one_test = one_ae.evaluate(X_one_test, X_one_test)\n",
    "eval_one_train, eval_one_validate, eval_one_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_one_imgs_train = one_encoder.predict(X_one_train)\n",
    "encoded_one_imgs_validate = one_encoder.predict(X_one_validate)\n",
    "encoded_one_imgs_test = one_encoder.predict(X_one_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructed \"1\" with auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_one_imgs = one_decoder.predict(encoded_one_imgs_train)\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_one_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_one_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(os.path.join(\"imgs\", \"one-conv-ae.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstructed \"7\" (aka anomaly) with auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sevens_imgs = one_ae.predict(digit_data[7][0])\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(digit_data[7][0][i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_sevens_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(os.path.join(\"imgs\", \"seven-conv-one-ae.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly detection with root of squared loss per pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_per_img(img,rec_img):\n",
    "    return np.sqrt(np.sum(np.power(rec_img - img,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_losses = np.array([])\n",
    "# for img in digit_data[7][0]:\n",
    "\n",
    "\n",
    "sevens = digit_data[7][0]\n",
    "imgs = sevens.reshape(-1, 28, 28, 1)\n",
    "rec_imgs = one_ae.predict(imgs)\n",
    "seven_losses = np.array([loss_per_img(i, ri) for i, ri in zip(imgs, rec_imgs)])\n",
    "\n",
    "# imgs = all_digits#.reshape(-1,28,28,1)\n",
    "# rec_imgs = one_ae.predict(imgs)\n",
    "# all_digits_losses = np.array([loss_per_img(i,ri) for i,ri in zip(imgs,rec_imgs)])\n",
    "\n",
    "seven_losses.max(), seven_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_losses = np.array([])\n",
    "imgs = X_one_test.reshape(len(X_one_test),28,28,1)\n",
    "rec_imgs = one_ae.predict(imgs)\n",
    "normal_losses = np.array([loss_per_img(i,ri) for i,ri in zip(imgs,rec_imgs)])\n",
    "\n",
    "normal_losses.max(), normal_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss distribution over the normal dataset\n",
    "bins = 100\n",
    "t = np.linspace(0, normal_losses.max(), bins)\n",
    "hist_normal = np.histogram(normal_losses, bins=bins)\n",
    "plt.plot(t, hist_normal[0] / len(normal_losses), \"b\")\n",
    "\n",
    "# loss distribution over the anomaly dataset for digit \"seven\"\n",
    "hist_sevens = np.histogram(seven_losses, bins=bins)\n",
    "t = np.linspace(0, seven_losses.max(), bins)\n",
    "plt.plot(t, hist_sevens[0] / len(seven_losses), \"r\")\n",
    "\n",
    "# loss distribution over the anomaly dataset for all digits\n",
    "hist_all = np.histogram(all_digits_losses, bins=bins)\n",
    "t = np.linspace(0, all_digits_losses.max(), bins)\n",
    "plt.plot(t, hist_all[0] / len(all_digits_losses), \"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss distribution over the anomaly dataset\n",
    "bins = 100\n",
    "hist_anomaly = np.histogram(seven_losses, bins=bins)\n",
    "t = np.linspace(0, seven_losses.max(), bins)\n",
    "plt.plot(t, hist_anomaly[0], \"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x:= \"false detected anomalies in %\"\n",
    "# y:= \"correct detected normal data points in %\"\n",
    "rs = []\n",
    "prec = 1000\n",
    "step_size = 1 / prec\n",
    "decs = np.arange(0.9, 1, step_size)\n",
    "for i in decs:  # i == 0.98 seems to be a valid value\n",
    "    loss_boundary = np.sort(normal_losses)[\n",
    "        int(len(normal_losses) * i)\n",
    "    ]  # loss value for detection of i% normal data points\n",
    "    x = seven_losses[\n",
    "        np.where(seven_losses < loss_boundary)\n",
    "    ]  # loss values for anomalies which are below than the boundary\n",
    "    ratio_of_undetected = len(x) / len(\n",
    "        seven_losses\n",
    "    )  # ratio between not detected loss values for anomalies\n",
    "    rs = np.append(rs, ratio_of_undetected)\n",
    "    if (int(i * prec)) % int(prec / 200) == 0:\n",
    "        print(\n",
    "            \"i:%.3f * ratio:%.3f = %.3f\"\n",
    "            % (i, ratio_of_undetected, i * ratio_of_undetected)\n",
    "        )\n",
    "plt.plot(rs, decs)  # ,zs=decs*rs)\n",
    "plt.grid()\n",
    "plt.xlabel(\"FALSE POSITIVE RATE\")\n",
    "plt.ylabel(\"TRUE POSITIVE RATE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_boundary = np.sort(normal_losses)[int(len(normal_losses) * 0.98)]\n",
    "ind_undetected_anomalies = np.where(\n",
    "    seven_losses < loss_boundary\n",
    ")  # indices for undetected anomalies in the data set\n",
    "ind_detected_normals = np.where(\n",
    "    normal_losses >= loss_boundary\n",
    ")  # indices for as anomaly detected normal data points in the data set\n",
    "\n",
    "detected_normals = X_one_test[ind_detected_normals]\n",
    "undetected_anomalies = digit_data[7][0][ind_undetected_anomalies]\n",
    "loss_boundary, len(detected_normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(undetected_anomalies)  # how many digits we will display\n",
    "plt.figure(figsize=(40, 32))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(n/5, n/4, i + 1)\n",
    "    plt.imshow(undetected_anomalies[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(os.path.join(\"imgs\", \"undetected-sevens.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display digits \"1\" which have been detectes as normaility \n",
    "n = len(detected_normals)  # how many digits we will display\n",
    "plt.figure(figsize=(40, 32))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(n/5, n/4, i + 1)\n",
    "    plt.imshow(detected_normals[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(os.path.join(\"imgs\", \"detected-ones.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_one_test[np.argmax(normal_losses)].reshape((28,28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(digit_data[7][0][np.argmax(seven_losses)].reshape((28,28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Anomaly Detector\n",
    "This anomaly detector should be able to seperate images of the handwritten digits $1$ and $7$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def is_anomaly(ae, x):\n",
    "    x = x.reshape((1,28,28,1))\n",
    "    pred = ae.predict(x)\n",
    "    loss = np.sum(pred - x) **2 # squared loss => positive value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All digits classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = np.prod(encoded_imgs_train.shape[1:], dtype=np.int64)\n",
    "encoded_imgs_train = encoded_imgs_train.reshape(len(encoded_imgs_train), flat)\n",
    "encoded_imgs_validate = encoded_imgs_validate.reshape(\n",
    "    len(encoded_imgs_validate), flat)\n",
    "encoded_imgs_test = encoded_imgs_test.reshape(len(encoded_imgs_test), flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_loc = os.path.join(CUR_DIR, \"ckpts\", \"classifier.hdf5\")\n",
    "if os.path.isfile(ckpt_loc):\n",
    "    print(\"Loading classifier from directory %s...\" % ckpt_loc)\n",
    "    classifier = load_model(ckpt_loc)\n",
    "else:\n",
    "    print(\"Training classifier...\")\n",
    "    classifier = build_classifier(input_dim=flat)\n",
    "    earlyStopping = EarlyStopping(\n",
    "        monitor=\"val_acc\", patience=5, verbose=1, mode=\"max\", min_delta=0.0005\n",
    "    )\n",
    "    mcp_save = ModelCheckpoint(\n",
    "        ckpt_loc, save_best_only=True, verbose=1, monitor=\"val_acc\", mode=\"max\"\n",
    "    )\n",
    "    reduce_lr_loss = ReduceLROnPlateau(\n",
    "        monitor=\"val_acc\", factor=0.3, patience=3, verbose=1, mode=\"max\"\n",
    "    )\n",
    "    classifier.fit(\n",
    "        encoded_imgs_train,\n",
    "        y_train,\n",
    "        validation_data=(encoded_imgs_validate, y_validate),\n",
    "        batch_size=16,\n",
    "        epochs=32,\n",
    "        shuffle=True,\n",
    "        callbacks=[earlyStopping, mcp_save, reduce_lr_loss],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_train = classifier.evaluate(encoded_imgs_train, y_train)\n",
    "eval_validate = classifier.evaluate(encoded_imgs_validate, y_validate)\n",
    "eval_test = classifier.evaluate(encoded_imgs_test, y_test)\n",
    "eval_train,eval_validate, eval_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cm(input, y_true):\n",
    "    \"\"\"Computes confusion matrix.\"\"\"\n",
    "    y_pred = tf.argmax(classifier.predict(input), axis=1)\n",
    "    y_true = tf.argmax(y_true, axis=1)\n",
    "\n",
    "    c = tf.keras.backend.eval(y_pred)\n",
    "    d = tf.keras.backend.eval(y_true)\n",
    "\n",
    "    return confusion_matrix(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(cm):\n",
    "    results = []\n",
    "    for i in range(len(cm)):  # rows\n",
    "        TP = cm[i][i]\n",
    "        fp_tp = np.sum(cm[i])\n",
    "        results.append(TP / fp_tp)\n",
    "    return results + [np.mean(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(cm):\n",
    "    results = []\n",
    "    for i in range(len(cm)):  # rows\n",
    "        TP = cm[i][i]\n",
    "        tp_fn = 0\n",
    "        for j in range(len(cm[i])):\n",
    "            tp_fn += cm[j][i]\n",
    "        results.append(TP/tp_fn)\n",
    "    return results + [np.mean(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = get_cm(encoded_imgs_train, y_train)\n",
    "print(cm_train, precision(cm_train)[-1], recall(cm_train)[-1], sep=\"\\n\")\n",
    "\n",
    "cm_validate = get_cm(encoded_imgs_validate, y_validate)\n",
    "print(cm_validate, precision(cm_validate)[-1], recall(cm_validate)[-1], sep=\"\\n\")\n",
    "\n",
    "cm_test = get_cm(encoded_imgs_test, y_test)\n",
    "print(cm_test, precision(cm_test)[-1], recall(cm_test)[-1], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection with DJ CF Gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_flat = np.prod(encoded_one_imgs_train.shape[1:], dtype=np.int64)\n",
    "encoded_one_imgs_train = encoded_one_imgs_train.reshape(\n",
    "    len(encoded_one_imgs_train), one_flat\n",
    ")\n",
    "encoded_one_imgs_validate = encoded_one_imgs_validate.reshape(\n",
    "    len(encoded_one_imgs_validate), one_flat\n",
    ")\n",
    "encoded_one_imgs_test = encoded_one_imgs_test.reshape(\n",
    "    len(encoded_one_imgs_test), one_flat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x_i, my_i, sigma_i2):\n",
    "    # gaussian distribution for one feature\n",
    "    if sigma_i2 == 0:\n",
    "        return 1 if x_i == my_i else 0\n",
    "    return np.array(\n",
    "        (1 / np.sqrt(2 * np.pi * sigma_i2))\n",
    "        * np.exp(-(x_i - my_i) ** 2 / (2 * sigma_i2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my(X):\n",
    "    return np.array([(1 / len(x)) * np.sum(x) for x in X.T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma2(X, my):\n",
    "    # computes sigma squared for each feature\n",
    "    m = len(X)  # number of data points\n",
    "    return np.array([(1/m)*np.sum((X[:, i] - my[i]) ** 2) for i in range(len(my))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(X,my,sigma2):\n",
    "    return np.array([np.prod([gauss(x[i], my[i], sigma2[i])\n",
    "               for i in range(len(x))]) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_one_imgs_train\n",
    "m = len(X)\n",
    "number_of_features = len(X[0])\n",
    "my = np.array([(1 / len(x)) * np.sum(x) for x in X.T])\n",
    "sigma_2 = np.array(\n",
    "    [np.sum((X[:, i] - my[i]) ** 2) / m for i in range(number_of_features)]\n",
    ")\n",
    "\n",
    "p_all = np.sort(p(X, my, sigma_2))\n",
    "epsilon = 1e-7\n",
    "thresholded_P = p_all[np.where(p_all > epsilon)]\n",
    "len(thresholded_P) / len(p_all), my, sigma_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(len(my)):\n",
    "    # plots distribution of i-th feature\n",
    "    # display original\n",
    "    bins = 51\n",
    "    hist = np.histogram(X[:, i], bins=bins)\n",
    "    ax = plt.subplot(4, 6, i + 1)\n",
    "    h_min = min(hist[1])\n",
    "    h_max = max(hist[1])\n",
    "    delta = abs(h_max - h_min)\n",
    "    step = delta / (bins)\n",
    "    r = np.arange(h_min, h_max, step)\n",
    "    plt.plot(r, hist[0])\n",
    "    print(r, hist[0], step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_values_to_img(values):\n",
    "    values = np.reshape(values, (1, 2, 2, 6))\n",
    "    random_img = decoder.predict(values)\n",
    "    return np.reshape(random_img, (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 50\n",
    "hist_all = np.histogram(p_all, bins=bins)\n",
    "h_min = min(hist_all[1])\n",
    "h_max = max(hist_all[1])\n",
    "delta = abs(h_max - h_min)\n",
    "r = np.arange(h_min, h_max, delta / bins)\n",
    "plt.plot(r, hist_all[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting fashion-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion():\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    img = X_train[0].reshape((28, 28))\n",
    "    # reshape data to fit model\n",
    "    plt.imshow(X_train[1], cmap=\"Greys\", vmin=0, vmax=255)\n",
    "    plt.savefig(\"fashion_example_img.png\")\n",
    "\n",
    "    \"\"\"for Autoencoder\"\"\"\n",
    "    X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "    X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "    # np.random.shuffle(X_test)\n",
    "    X_validate = X_test[len(X_test) // 2 :]\n",
    "    X_test = X_test[: len(X_test) // 2]\n",
    "\n",
    "    return X_train / 255.0, X_test / 255.0, X_validate / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fashion_train, X_fashion_test, X_fashion_validate = get_fashion()\n",
    "print(X_fashion_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colored images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dic = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(CUR_DIR, \"data\", \"cifar-10-batches-py\")\n",
    "train_batches = []\n",
    "test_batch = []\n",
    "for filename in os.listdir(data_path):\n",
    "    filename = os.path.join(data_path, filename)\n",
    "    if \"data_batch\" in filename:\n",
    "        train_batches.append(unpickle(filename))  # keys: labels, data, filenames\n",
    "    if \"test_batch\" in filename:\n",
    "        test_batch = unpickle(filename)\n",
    "len(train_batches), test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(CUR_DIR, \"data\", \"cifar-100-python\")\n",
    "train_batches = []\n",
    "test_batch = []\n",
    "for filename in os.listdir(data_path):\n",
    "    filename = os.path.join(data_path, filename)\n",
    "    if \"train\" in filename:\n",
    "        train_batches = unpickle(filename)  # keys: labels, data, filenames\n",
    "    if \"test\" in filename:\n",
    "        test_batch = unpickle(filename)\n",
    "len(train_batches), test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
